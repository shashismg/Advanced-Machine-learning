# 🚀 Advanced Machine Learning Models – AdaBoost | XGBoost | CatBoost

Hey there! 👋  
This repo contains my exploration of some **advanced ensemble learning models** that are widely used in modern ML competitions and real-world applications:

- ⚡ AdaBoost
- 🚀 XGBoost
- 🐈 CatBoost

These models are all about **boosting** — improving weak learners into strong ones. This repo helped me understand the intuition behind them, how to use them in Python, and how to tune them for better performance.

---

## 📁 Files Overview

| File | Model Explored |
|------|----------------|
| `adaboost_basics.ipynb` | Intro to AdaBoost using Decision Trees as base estimators |
| `xgboost_basics.ipynb` | XGBoost implementation + feature importance visualization |
| `catboost_basics.ipynb` | CatBoost for handling categorical features effectively |

Each notebook includes:
- Model intuition and how boosting works  
- Code implementation using real datasets  
- Evaluation with accuracy, confusion matrix, ROC curves, etc.  
- A bit of hyperparameter tuning where possible  

---

## 🛠️ Tools & Libraries Used

- Python 3.x
- Scikit-learn
- XGBoost
- CatBoost
- Pandas, NumPy
- Matplotlib, Seaborn

---

## 🎯 Why This Repo?

This is just part of my learning log — not production code or a fancy tutorial.  
I built these to:
- Get familiar with the boosting technique  
- Learn the differences between AdaBoost, XGBoost, and CatBoost  
- Practice model training, evaluation, and comparison

---


> _“Boost your knowledge, one weak learner at a time.”_
